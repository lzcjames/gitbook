# Note 08/09/2022

## Google Cloud offerings
![](https://i.imgur.com/UDYMpN1.png)
Google Cloud offerings can be broadly categorized as compute, storage, big data, and  machine learning services for web, mobile, analytics, and backend solutions.The main  focus of this course is on big data and machine learning.
Google Cloud 提供的服务可以大致分为计算、存储、大数据和机器学习服务，用于 Web、移动、分析和后端解决方案。本课程的主要重点是大数据和机器学习。

![](https://i.imgur.com/xhCV92v.png)

There are 5 modules in today’s course, rounded off with a short summary and review  session.

下面是我们的日程安排: 在第一个模块中，您将了解 Google Cloud 上的大数据和机器学习。这包括 Google Cloud 的基础设施、大数据和机器学习产品。

Here’s our agenda:
- In the ﬁrst module, you’ll be introduced to big data and machine learning on Google Cloud. This includes Google Cloud’s infrastructure and big data and machine learning products.
在第一个模块中，您将了解 GoogleCloud 上的大数据和机器学习。这包括 Google Cloud 的基础设施、大数据和机器学习产品。
- In the second module of the course, you’ll explore data engineering for -streaming data. This includes how to build a streaming data pipeline, from ingestion with Pub/Sub, to processing with Dataﬂow, and ﬁnally, to visualization using Data Studio and Looker.
在本课程的第二个模块中，您将探索流数据的数据工程。这包括如何构建流式数据管道，从使用 Pub/Sub 进行摄取，到使用 Dataflow 进行处理，最后到使用 Data Studio 和 Looker 进行可视化。
- After that, you’ll explore big data with BigQuery, Google’s popular data warehouse tool, and BigQuery ML, the embedded ML functionality used for developing machine learning models directly in BigQuery.
之后，您将使用 BigQuery (谷歌流行的数据仓库工具)和 BigQuery ML (用于直接在 BigQuery 中开发机器学习模型的嵌入式机器学习功能)来探索大数据。
- From there, you’ll compare the four options provided by Google Cloud to build and deploy a machine learning model.
从那里开始，您将比较 Google Cloud 提供的构建和部署机器学习模型的四个选项。
- And in the ﬁnal module of the course, you’ll learn how to build a machine learning workﬂow from start to ﬁnish using Vertex AI, a uniﬁed platform that brings all the components of the machine learning ecosystem and workﬂow together.
在本课程的最后一个模块中，您将学习如何使用 Vertex AI 从头到尾构建一个机器学习工作流，这是一个统一的平台，将机器学习生态系统的所有组件和工作流结合在一起。


# 1. Big Data and Machine Learning on Google Cloud
Module 1
Google Cloud Big Data and Machine Learning Fundamentals


![](https://i.imgur.com/lOSc23R.png)

Welcome to the ﬁrst module of the Big Data and Machine Learning Fundamentals  course! This module lays the foundation to the next four modules,
- Data engineering
    - M.2: Data engineering for streaming data
    - M.3: Big data with BigQuery
- Machine learning
    - M.4: Machine learning options
    - M.5: The Machine Learning workﬂow with Vertex AI

## 1.1 Introduction
![](https://i.imgur.com/CH2PF6j.png)
You can think of the Google Cloud infrastructure in terms of three layers.

- At the base layer is networking and security, which lays the foundation to  support all of Google’s infrastructure and applications.
- On the next layer sit compute and storage. Google Cloud separates, or  decouples, as it’s technically called, compute and storage so they can scale  independently based on need.
- And on the top layer sit the big data and machine learning products, which  enable you to perform tasks to ingest, store, process, and deliver business  insights, data pipelines, and ML models.

And thanks to Google Cloud, these tasks can be accomplished without needing to  manage and scale the underlying infrastructure.

![](https://i.imgur.com/02R7bJs.png)
This course focuses on the middle layer, compute and storage, and the top layer, big  data and machine learning products.

Networking and security fall outside of the focus of this course, but if you’re  interested in learning more you can explore cloud.google.com/training for more  options.

## 1.2 Compute

![](https://i.imgur.com/e1WTEKy.png)

Let’s focus our attention on the middle layer of the Google Cloud infrastructure,
compute and storage. We’ll begin with compute.

![](https://i.imgur.com/a596Ho1.png)

Organizations with growing data needs often require lots of compute power to run big  data jobs. And as organizations design for the future, the need for compute power  only grows.

Google offers a range of computing services, which includes: Compute Engine,  Google Kubernetes Engine, App Engine, Cloud Functions, and Cloud Run.

![](https://i.imgur.com/6D1EbnA.png)

Let’s start with Compute Engine.

Compute Engine is an IaaS offering, or infrastructure as a service, which provides raw  compute, storage, and network capabilities organized virtually into resources that are  similar to physical data centers. It provides maximum ﬂexibility for those who prefer  to manage server instances themselves.

![](https://i.imgur.com/hWuJvrW.png)

The second is Google Kubernetes Engine, or GKE.

GKE runs containerized applications in a cloud environment, as opposed to on an  individual virtual machine, like Compute Engine. A container represents code  packaged up with all its dependencies.

![](https://i.imgur.com/OMMzB5h.png)

The third computing service offered by Google is App Engine, a fully managed PaaS  offering, or platform as a service. PaaS offerings bind code to libraries that provide  access to the infrastructure application needs. This allows more resources to be  focused on application logic.

![](https://i.imgur.com/fhs586D.png)

The fourth is Cloud Functions, which executes code in response to events, like when a  new ﬁle is uploaded to Cloud Storage. It’s a completely serverless execution  environment, often referred to as functions as a service.

![](https://i.imgur.com/Ek2ZHs7.png)

And ﬁnally there is Cloud Run, a fully managed compute platform that enables you to  run request or event-driven stateless workloads without having to worry about  servers. It abstracts away all infrastructure management so you can focus on writing  code. It automatically scales up and down from zero, so you never have to worry  about scale configuration.

Cloud Run charges you only for the resources you use so you never pay for over  provisioned resources.

![](https://i.imgur.com/Vq9Hlhc.png)

Google Photos offers a feature called automatic video stabilization. This takes an  unstable video, like one captured while riding on the back of a motorbike, and  stabilizes it to minimize movement.

Let’s look at an example of a technology that requires a lot of compute power.

![](https://i.imgur.com/lLwtAtQ.jpg)

![](https://i.imgur.com/SaSwyCF.png)

For this feature to work as intended, you need the proper data. This includes the video  itself, which is really a large collection of individual images, along with time series  data on the camera’s position and orientation from the onboard gyroscope, and  motion from the camera lens.

A short video can require over a billion data points to feed the ML model to create a  stabilized version. As of 2020, roughly 28 billion photos and videos were uploaded to  Google Photos every week, with more than four trillion photos in total stored in the  service.

![](https://i.imgur.com/nyHptx4.png)

To ensure that this feature works as intended, and accurately, the Google Photos team  needed to develop, train, and serve a high-performing machine learning model on  millions of videos. That’s a large training dataset!

![](https://i.imgur.com/lhJ4JS6.png)

Just as the hardware on a standard personal computer might not be powerful enough  to process a big data job for an organization, the hardware on a smartphone is not  powerful enough to train sophisticated ML models.

That’s why Google trains production machine learning models on a vast network of  data centers, only to then deploy smaller, trained versions of the models to the  smartphone and personal computer hardware.

![](https://i.imgur.com/1x6aR3G.png)

But where does all that processing power come from?

According to Stanford University’s 2019 AI index report, before 2012, artiﬁcial  intelligence results tracked closely with Moore’s Law, with the required computing  power used in the largest AI training runs doubling every two years. The report states  that, since 2012, the required computing power has been doubling approximately  every three and a half months.

![](https://i.imgur.com/WBelgd6.png)

This means that hardware manufacturers have run up against limitations, and CPUs,  which are central processing units, and GPUs, which are graphics processing units,  can no longer scale to adequately reach the rapid demand for ML.

![](https://i.imgur.com/Svq38Ml.png)

To help overcome this challenge, in 2016 Google introduced the Tensor Processing  Unit, or TPU. TPUs are Google’s custom-developed application-speciﬁc integrated  circuits (ASICs) used to accelerate machine learning workloads.

TPUs act as domain-speciﬁc hardware, as opposed to general-purpose hardware  with CPUs and GPUs. This allows for higher eﬃciency by tailoring architecture to meet  the computation needs in a domain, such as the matrix multiplication in machine learning.

![](https://i.imgur.com/vzbZ3Cc.png)

With TPUs, the computing speed increases more than 200 times.

This means that instead of waiting 26 hours for results with a single state-of-art GPU,  you’ll only need to wait for 7.9 minutes for a full Cloud TPU v.2 pod to deliver the same  results.

Cloud TPUs have been integrated across Google products, and this state-of-the-art  hardware and supercomputing technology is available with Google Cloud products  and services.

## 1.3 Storage

![](https://i.imgur.com/wmzp0my.png)
Now that we’ve explored compute and why it’s needed for big data and ML jobs, let’s  now examine storage.

![](https://i.imgur.com/sf0OfR9.png)

For proper scaling capabilities, compute and storage are decoupled. This is one of the  major differences between cloud computing and desktop computing.

With cloud computing, processing limitations aren’t attached to storage disks.

![](https://i.imgur.com/wRZCPGJ.png)

Most applications require a database and storage solution of some kind.

With Compute Engine, for example, which was mentioned previously, you can install  and run a database on a virtual machine, just as you would do in a data center.

![](https://i.imgur.com/6UIY94M.png)


These include:
- Cloud Storage
- Cloud Bigtable
- Cloud SQL
- Cloud Spanner, and
- Firestore
- BigQuery

The goal of these products is to reduce the time and effort needed to store data. This  means creating an elastic storage bucket directly in a web interface or through a  command line for example on Google Cloud Storage.

![](https://i.imgur.com/HW0pn3g.png)


Google Cloud offers relational and non-relational databases, and worldwide object  storage.

Choosing the right option to store and process data often depends on the data type  that needs to be stored and the business need.

![](https://i.imgur.com/BMreQXJ.png)

Let’s start with unstructured versus structured data.

Unstructured data is information stored in a non-tabular form such as documents,  images, and audio ﬁles. Unstructured data is usually best suited to Cloud Storage.

![](https://i.imgur.com/PykTLRk.png)

Cloud Storage has four primary storage classes.
- The ﬁrst is Standard Storage. Standard Storage is considered best for  frequently accessed, or “hot,” data. It’s also great for data that is stored for  only brief periods of time.
- The second storage class is Nearline Storage. This is best for storing  infrequently accessed data, like reading or modifying data once per month or  less, on average. Examples include data backups, long-tail multimedia content,  or data archiving.
- The third storage class is Coldline Storage. This is also a low-cost option for  storing infrequently accessed data. However, as compared to Nearline  Storage, Coldline Storage is meant for reading or modifying data, at most,  once every 90 days.
- The fourth storage class is Archive Storage. This is the lowest-cost option,  used ideally for data archiving, online backup, and disaster recovery. It’s the  best choice for data that you plan to access less than once a year, because it  has higher costs for data access and operations and a 365-day minimum  storage duration.

![](https://i.imgur.com/d0IcMZ0.png)
Alternatively, there is structured data, which represents information stored in tables,  rows, and columns.

![](https://i.imgur.com/yUdaQ5A.png)

Structured data comes in two types: transactional workloads and analytical
workloads.

- Transactional workloads stem from Online Transaction Processing systems,  which are used when fast data inserts and updates are required to build
row-based records. This is usually to maintain a system snapshot. They  require relatively standardized queries that impact only a few records.
    - So, if your data is transactional and you need to access it using SQL,  then Cloud SQL and Cloud Spanner are two options.
        - Cloud SQL works best for local to regional scalability,
        - while Cloud Spanner, it best to scale a database globally.
    - If the transactional data will be accessed without SQL,
        - Firestore might be the best option. Firestore is a transactional  No-SQL, document-oriented database.

- Then there are analytical workloads, which stem from Online Analytical  Processing systems, which are used when entire datasets need to be read.  They often require complex queries, for example, aggregations.
    - If you have analytical workloads that require SQL commands, BigQuery  is likely the best option. BigQuery, Google’s data warehouse solution,  lets you analyze petabyte-scale datasets.
    - Alternatively, Cloud Bigtable provides a scalable NoSQL solution for  analytical workloads. It’s best for real-time, high-throughput  applications that require only millisecond latency.

## 1.4 The history of big  data and ML products
![](https://i.imgur.com/YRqtXp0.png)

![](https://i.imgur.com/WYSM6hU.png)

The ﬁnal layer of the Google Cloud infrastructure that is left to explore is big data and  machine learning products.

We’ll examine the evolution of data processing frameworks through the lens of  product development. Understanding the chronology of products can help address  typical big data and machine learning challenges.

![](https://i.imgur.com/Oc3KKsz.png)
Historically speaking, Google experienced challenges related to big data quite  early–mostly with large datasets, fast-changing data, and varied data. This was the  result of needing to index the World Wide Web.

And as the internet grew, Google needed to invent new data processing methods.

- So, in 2002, Google released the Google File System, or GFS. GFS was  designed to handle data sharing and petabyte storage at scale. It served as  the foundation for Cloud Storage and also what would become the managed  storage functionality in BigQuery.

- A challenge that Google was facing around this time was how to index the  exploding volume of content on the web. To solve this, in 2004 Google wrote a  report that introduced MapReduce. MapReduce was a new style of data  processing designed to manage large-scale data processing across big  clusters of commodity servers.

- As Google continued to grow, new challenges arose, speciﬁcally with recording  and retrieving millions of streaming user actions with high throughput. The  solution was the release in 2005 of Cloud Bigtable, a high-performance NoSQL  database service for large analytical and operational workloads.

With MapReduce available, some developers were restricted by the need to write code  to manage their infrastructure, which prevented them from focusing on applicationlogic.

As a result, from 2008 to 2010, Google started to move away from MapReduce as the  solution to process and query large datasets.

- So, in 2008, Dremel was introduced. Dremel took a new approach to big-data  processing by breaking the data into smaller chunks called shards, and then  compressing them.
- Dremel then uses a query optimizer to share tasks between the many shards  of data and the Google data centers, which processed queries and delivered results.  The big innovation was that Dremel autoscaled to meet query demands.
Dremel became the query engine behind BigQuery.

Google continued innovating to solve big data and machine learning challenges.  Some of the technology solutions released include:

- Colossus, in 2010, which is a cluster-level ﬁle system and successor to the  Google File System.
- BigQuery, in 2010 as well, which is a fully-managed, serverless data  warehouse that enables scalable analysis over petabytes of data. It is a  - - Platform as a Service (PaaS) that supports querying using ANSI SQL. It also  has built-in machine learning capabilities. BigQuery was announced in May  2010 and made generally available in November 2011.
- Spanner, in 2012, which is a globally available and scalable relational  database.
- Pub/Sub, in 2015, which is a service used for streaming analytics and data  integration pipelines to ingest and distribute data.

And TensorFlow, also in 2015, which is a free and open source software library for  machine learning and artiﬁcial intelligence.

- 2018 brought the release of the Tensor Processing Unit, or TPU, which you’ll  recall from earlier, and
- AutoML, as a suite of machine learning products.
- The list goes on till Vertex AI, a uniﬁed ML platform released in 2021.


![](https://i.imgur.com/u1BsC0B.png)

And it’s thanks to these technologies that the big data and machine learning product  line is now robust.

This includes:

- Cloud Storage
- Dataproc
- Cloud Bigtable
- BigQuery
- Dataﬂow
- Firestore
- Pub/Sub
- Looker
- Cloud Spanner
- AutoML, and
- Vertex AI, the uniﬁed platform

These products and services are made available through Google Cloud, and you’ll get  hands-on practice with some of them as part of this course.

## 1.5 Big data and ML  product categories
![](https://i.imgur.com/gs15WHr.png)

![](https://i.imgur.com/ulXkloq.png)

As we explored previously, Google offers a range of big data and machine learning  products. So, how do you know which is best for your business needs?

Let’s look closer at the list of products, which can be divided into four general  categories along the data-to-AI workﬂow: ingestion and process, storage, analytics,  and machine learning.

Understanding these product categories can help narrow down your choice.

![](https://i.imgur.com/hd3ZT3v.png)

The ﬁrst category is ingestion and process, which include products that are used to  digest both real-time and batch data. The list includes:

- Pub/Sub
- Dataﬂow
- Dataproc
- Cloud Data Fusion

You’ll explore how Dataﬂow and Pub/Sub can ingest streaming data later in this  course.

![](https://i.imgur.com/nOsiHQN.png)

The second product category is data storage, and you’ll recall from earlier that there  are ﬁve storage products:

- Cloud Storage
- Cloud SQL
- Cloud Spanner
- Cloud Bigtable, and
- Firestore

Cloud SQL and Cloud Spanner are relational databases, while Bigtable and Firestore  are NoSQL databases.

![](https://i.imgur.com/1IqEuwW.png)

The third product category is analytics. The major analytics tool is BigQuery. BigQuery  is a fully managed data warehouse that can be used to analyze data through SQL  commands.

In addition to BigQuery, you can analyze data and visualize results using:
- Google Data Studio, and
- Looker

You’ll explore BigQuery, Looker, and Data Studio in this course.

![](https://i.imgur.com/MOMQ6RS.png)

And the ﬁnal product category is machine learning, or ML. ML products include both  the ML development platform and the AI solutions:

The primary product of the ML development platform is Vertex AI, which includes:
- AutoML,
- Vertex AI Workbench, and
- TensorFlow

You’ll explore Vertex AI and AutoML in this course.

![](https://i.imgur.com/2STMkLt.png)

AI solutions are built on the ML development platform and include state-of-the-art  products to meet both horizontal and vertical market needs. These include:
- Document AI
- Contact Center AI
- Retail Product Discovery, and
- Healthcare Data Engine

These products unlock insights that only large amounts of data can provide. We’ll  explore the machine learning options and workﬂow together with these products in  greater detail later.

## 1.6 Customer example:  Gojek



